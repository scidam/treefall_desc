{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treefalls basic statistical analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The document descibes natural disturbances in stands caused by winds. We are trying to estimate the amount of such disturbances using different numerical measures, such as area of disturbances vs. geomorphological variables (height above sea level, slope, aspect, local gaussian curvature. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The section defines parameters that will allow to get access to the data: DEM and DEM-derived data, treefalls masked arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "datadir = './data'\n",
    "data_mapper = {'kunashir': {'box' : [4838720, 4935728, 369720, 468775], \n",
    "                            'data': {'height': 'kunUTM.tif',\n",
    "                                     'curvature': 'vars_kun/Curvatu_kun.tif',\n",
    "                                     'slope': 'vars_kun/Slope_kun.tif',\n",
    "                                     'aspect': 'vars_kun/Aspect_kun.tif',\n",
    "                                     'treefall': 'tiff_windfalls/windfalls_500m2_sakh_kur_Pol1.tif',\n",
    "                                     'cover': 'forest_cover.tif',\n",
    "                                     'biomass': 'biomass.tif'\n",
    "                                    }\n",
    "                                    },\n",
    "               'sakhalin': {'box': [5086970, 5377762, 85000, 243321],\n",
    "                            'data': {'height': 'sakhUTM.tif',\n",
    "                            'curvature': 'vars_sakh/Curvatu.tif',\n",
    "                            'slope': 'vars_sakh/Slope.tif',\n",
    "                            'aspect': 'vars_sakh/Aspect.tif',\n",
    "                            'treefall': 'tiff_windfalls/windfalls_500m2_sakh_kur_Pol1.tif',\n",
    "                            'cover': 'forest_cover.tif',\n",
    "                            'biomass': 'biomass.tif'\n",
    "                                    }},\n",
    "               'iturup': {'box': [4915354, 5004258, 488455, 556985],\n",
    "                          'data':   {'height': 'kunUTM.tif',\n",
    "                                     'curvature': 'vars_kun/Curvatu_kun.tif',\n",
    "                                     'slope': 'vars_kun/Slope_kun.tif',\n",
    "                                     'aspect': 'vars_kun/Aspect_kun.tif',\n",
    "                                     'treefall': 'tiff_windfalls/windfalls_500m2_sakh_kur_Pol1.tif',\n",
    "                                     'cover': 'forest_cover.tif',\n",
    "                                     'biomass': 'biomass.tif'\n",
    "                                    }},\n",
    "               \n",
    "                'shikotan': {'box': [4835160, 4862724, 467084, 494377],\n",
    "                             'data': {'height': 'kunUTM.tif',\n",
    "                                     'curvature': 'vars_kun/Curvatu_kun.tif',\n",
    "                                     'slope': 'vars_kun/Slope_kun.tif',\n",
    "                                     'aspect': 'vars_kun/Aspect_kun.tif',\n",
    "                                     'treefall': 'tiff_windfalls/windfalls_500m2_sakh_kur_Pol1.tif',\n",
    "                                     'cover': 'forest_cover.tif',\n",
    "                                     'biomass': 'biomass.tif'\n",
    "                                    }}\n",
    "               \n",
    "               \n",
    "               \n",
    "               \n",
    "               \n",
    "               } \n",
    "\n",
    "for key in data_mapper:\n",
    "    for j in data_mapper[key]['data']:\n",
    "        data_mapper[key]['data'][j] = os.path.join(datadir, data_mapper[key]['data'][j])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliary functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define `gdal` based function used to perform basic i/o operations on spatial data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from osgeo import gdal\n",
    "from osgeo import osr\n",
    "\n",
    "def array_to_raster(array, lats, lons,  outputfilename, asfname):\n",
    "    \"\"\"Array > Raster\n",
    "    Save a raster from a C order array.\n",
    "\n",
    "    :param array: ndarray\n",
    "    \"\"\"\n",
    "    \n",
    "    SourceDS = gdal.Open(asfname, gdal.GA_ReadOnly)\n",
    "    Projection = osr.SpatialReference()\n",
    "    Projection.ImportFromWkt(SourceDS.GetProjectionRef())    \n",
    "    x_pixels, y_pixels = array.shape\n",
    "    XPIXEL_SIZE = (lons[1] - lons[0]) / float(x_pixels)\n",
    "    YPIXEL_SIZE = (lats[1] - lats[0]) / float(y_pixels)\n",
    "    x_min = np.min(lons)\n",
    "    y_max = np.max(lats)\n",
    "    driver = gdal.GetDriverByName('GTiff')\n",
    "    dataset = driver.Create(\n",
    "        outputfilename,\n",
    "        y_pixels,\n",
    "        x_pixels,\n",
    "        1,\n",
    "        gdal.GDT_Float32)\n",
    "\n",
    "    dataset.SetGeoTransform((\n",
    "        x_min,    # 0\n",
    "        abs(XPIXEL_SIZE),  # 1\n",
    "        0,                      # 2\n",
    "        y_max,    # 3\n",
    "        0,                      # 4\n",
    "        -abs(YPIXEL_SIZE)))\n",
    "    dataset.SetProjection(Projection.ExportToWkt())\n",
    "    dataset.GetRasterBand(1).WriteArray(array)\n",
    "    dataset.FlushCache()  # Write to disk.\n",
    "    return 0\n",
    "\n",
    "\n",
    "def get_data_by_coordinate_np(lats, lons, array, xmin, xres, ymax, yres):\n",
    "    \"\"\"Just a helper function\"\"\"\n",
    "    lat_inds = ((lats - ymax) / yres).astype(np.int16)\n",
    "    lon_inds = ((lons - xmin) / xres).astype(np.int16)\n",
    "    array = array[lat_inds, lon_inds]\n",
    "    return array\n",
    "\n",
    "\n",
    "def load_data(lats, lons, filename):\n",
    "    data = gdal.Open(filename)\n",
    "    geoinfo = data.GetGeoTransform()\n",
    "    xmin = geoinfo[0]\n",
    "    xres = geoinfo[1]\n",
    "    ymax = geoinfo[3]\n",
    "    yrot = geoinfo[4]\n",
    "    xrot = geoinfo[2]\n",
    "    yres = geoinfo[-1]\n",
    "    if not np.isclose(xrot, 0) or not np.isclose(yrot, 0):\n",
    "        raise BaseException(\"xrot and yrot should be 0\")\n",
    "    array = data.ReadAsArray()\n",
    "    del data\n",
    "    result = get_data_by_coordinate_np(np.array(lats, dtype=np.float64),\n",
    "                                  np.array(lons, dtype=np.float64),\n",
    "                                  array,\n",
    "                                  xmin, xres, ymax, yres)\n",
    "    return result\n",
    "\n",
    "\n",
    "def create_grid(area, dlat=50, dlon=50):\n",
    "    \"\"\"Returns raw meshgrid based on specified discretization parameters\n",
    "    \"\"\"\n",
    "    latmin, latmax, lonmin, lonmax = area\n",
    "    lats = np.arange(latmin, latmax, dlat)\n",
    "    lons = np.arange(lonmin, lonmax, dlon)\n",
    "    return np.meshgrid(lats, lons)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for specific data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_specific_data(area='sakhalin', spec='treefall', dlat=70, dlon=70):\n",
    "    \"\"\"Loads data and return flattened array\"\"\"\n",
    "    lats, lons = create_grid(data_mapper[area]['box'], dlat=dlat, dlon=dlon)\n",
    "    data = load_data(lats, lons, data_mapper[area]['data'][spec])\n",
    "    if spec == 'treefall':\n",
    "        nodata_value = 255\n",
    "        data[data==nodata_value] = 0\n",
    "    return data, lats, lons\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets do some tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for area in data_mapper:\n",
    "#     print(\"Explored area: \", area)\n",
    "#     data, lats, lons = load_specific_data(area=area, spec='height')\n",
    "#     print(data.shape, lats.shape, lons.shape)\n",
    "#     plt.imshow(data.T, origin='lower')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All tests are passed: we are ready to continue... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Area estimations, w/wo slope corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= sakhalin ==============\n",
      "TreeFall area is sq. km:  447.5976\n",
      "TreeFall area w/o slope correction, sq. km:  426.5842\n",
      "Total area is sq. km:  13126.598656\n",
      "Total area w/o slope correction, sq. km:  12604.2014\n",
      "==================================================\n",
      "========= iturup ==============\n",
      "TreeFall area is sq. km:  9.608503\n",
      "TreeFall area w/o slope correction, sq. km:  9.5697\n",
      "Total area is sq. km:  1023.57792\n",
      "Total area w/o slope correction, sq. km:  988.4084\n",
      "==================================================\n",
      "========= kunashir ==============\n",
      "TreeFall area is sq. km:  11.467949\n",
      "TreeFall area w/o slope correction, sq. km:  11.221\n",
      "Total area is sq. km:  1267.432576\n",
      "Total area w/o slope correction, sq. km:  1222.6137\n",
      "==================================================\n",
      "========= shikotan ==============\n",
      "TreeFall area is sq. km:  0.686\n",
      "TreeFall area w/o slope correction, sq. km:  0.686\n",
      "Total area is sq. km:  0.0\n",
      "Total area w/o slope correction, sq. km:  0.0\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "for area in data_mapper:\n",
    "    print(\"========= {} ==============\".format(area))\n",
    "    slopes, lats, lons = load_specific_data(area=area, spec='slope')\n",
    "    treefall, lats, lons = load_specific_data(area=area, spec='treefall')\n",
    "    cover, lats, lons = load_specific_data(area=area, spec='cover')\n",
    "    aspect, lats, lons = load_specific_data(area=area, spec='aspect')\n",
    "    lat_size, lon_size = abs(lats[0][1] - lats[0][0]), abs(lons[1][0] - lons[0][0])\n",
    "    all_data_indicies = ((aspect != -1) & (cover > 25))\n",
    "    print(\"TreeFall area is sq. km: \", ((lat_size * lon_size)/np.cos(slopes[treefall == 1]/180*np.pi)).sum()/10**6)\n",
    "    print(\"TreeFall area w/o slope correction, sq. km: \", (lat_size * lon_size*(treefall == 1).sum())/10**6)\n",
    "    print(\"Total area is sq. km: \", ((lat_size * lon_size)/np.cos(slopes[all_data_indicies]/180*np.pi)).sum()/10**6)\n",
    "    print(\"Total area w/o slope correction, sq. km: \", (lat_size * lon_size*(all_data_indicies).sum())/10**6)\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating area:  sakhalin\n"
     ]
    }
   ],
   "source": [
    "## Make connectivity regions\n",
    "from skimage.measure import label\n",
    "from collections import Counter\n",
    "\n",
    "for area in data_mapper:\n",
    "    print(\"Evaluating area: \", area)\n",
    "    treefall, lats, lons = load_specific_data(area=area, spec='treefall')\n",
    "    slopes, lats, lons = load_specific_data(area=area, spec='slope')\n",
    "    labels = label(treefall, connectivity=2)\n",
    "    res = []\n",
    "    lat_size, lon_size = abs(lats[0][1] - lats[0][0]), abs(lons[1][0] - lons[0][0])\n",
    "    for lab in np.unique(labels.ravel()):\n",
    "        res.append((lat_size*lon_size/np.cos(slopes[labels == lab])).sum())\n",
    "    print(Counter(labels.ravel()))\n",
    "    sdf\n",
    "    plt.hist(res, bins=10)\n",
    "    plt.title(\"Tree fall areas distribution\")\n",
    "    plt.savefig(\"%s_treefalls.png\"%area, dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treefalls diagram vs. relief characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ks_2samp\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "for area in data_mapper:\n",
    "    print(\"========= {} ==============\".format(area))\n",
    "    treefall, lats, lons = load_specific_data(area=area, spec='treefall')\n",
    "    cover, lats, lons = load_specific_data(area=area, spec='cover')\n",
    "    aspect, lats, lons = load_specific_data(area=area, spec='aspect')\n",
    "    biomass, lats, lons = load_specific_data(area=area, spec='biomass')\n",
    "    for var in ('height', 'aspect', 'slope'):\n",
    "        data, lats, lons = load_specific_data(area=area, spec=var)\n",
    "        all_data_indicies = ((aspect != -1) & (cover > 25)).ravel()\n",
    "        tree_fall_indicies = (treefall == 1).ravel()\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.hist(data[treefall == 1], bins=50, normed=True, color='gray')\n",
    "        plt.title(\"Area: {}\".format(area))\n",
    "        plt.gca().set_xlabel(str(var))\n",
    "        y_data, x_spec = np.histogram(data.ravel()[all_data_indicies], bins=50, density=True)\n",
    "        plt.gca().plot(x_spec[:-1], y_data, 'r')\n",
    "        plt.savefig(\"%s_%s_histoogram.png\" % (area, var), dpi=300)\n",
    "        print(\"Statistical comparison to all points\")\n",
    "        \n",
    "        # ------------ Select predefined number of points randomly ----------\n",
    "        a, b = np.random.choice(data.ravel()[tree_fall_indicies], size=int(tree_fall_indicies.sum() * 0.7)), \\\n",
    "               np.random.choice(data.ravel()[all_data_indicies], size=int(tree_fall_indicies.sum() * 0.7)),  \n",
    "        print(\"K-S test: \", ks_2samp(a, b))\n",
    "        \n",
    "        # ---------------- Biomass vs Parameters -----------------\n",
    "        f = plt.figure()\n",
    "        ax1 = f.add_subplot(121)\n",
    "        ax2 = f.add_subplot(122)\n",
    "        ax1.plot(data.ravel()[all_data_indicies], biomass.ravel()[all_data_indicies], '.')\n",
    "        ax1.set_title(\"Original biomass distribution\")\n",
    "        ax2.plot(data.ravel()[tree_fall_indicies], biomass.ravel()[tree_fall_indicies], '.')\n",
    "        ax2.set_title(\"Harvested biomass distribution\")\n",
    "        print(\"Harvested biomass total={}: mean={} +/- std={} \".format(biomass.ravel()[tree_fall_indicies].sum(), biomass.ravel()[tree_fall_indicies].mean(), biomass.ravel()[tree_fall_indicies].std()))\n",
    "        print(\"Total biomass total={}: mean={} +/- std={} \".format(biomass.ravel()[all_data_indicies].sum(), biomass.ravel()[all_data_indicies].mean(), biomass.ravel()[all_data_indicies].std()))\n",
    "        plt.savefig(\"%s_%s_biomass.png\" % (area, var), dpi=300)\n",
    "        print(\"=\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make connectivity regions\n",
    "from skimage.measure import label\n",
    "\n",
    "\n",
    "for area in data_mapper:\n",
    "    print(\"Evaluating area: \", area)\n",
    "    treefall, lats, lons = load_specific_data(area=area, spec='treefall')\n",
    "    slopes, lats, lons = load_specific_data(area=area, spec='slope')\n",
    "    labels = label(treefall, connectivity=2)\n",
    "    res = []\n",
    "    lat_size, lon_size = abs(lats[0][1] - lats[0][0]), abs(lons[1][0] - lons[0][0])\n",
    "    for lab in np.unique(labels.ravel()):\n",
    "        res.append((lat_size*lon_size/np.cos(slopes[labels == lab])).sum())\n",
    "    plt.hist(res, bins=50, normed=True)\n",
    "    plt.title(\"Tree fall areas distribution\")\n",
    "    plt.savefig(\"%s_treefalls.png\"%area, dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "# from sklearn.model_selection import cross_val_score, train_test_split\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# for area in data_mapper:\n",
    "#     print(\"========= {} ==============\".format(area))\n",
    "#     treefall, lats, lons = load_specific_data(area=area, spec='treefall')\n",
    "#     data, lats, lons = load_specific_data(area=area, spec='aspect')\n",
    "#     non_tree_fall_indicies = ((treefall != 1 ) & (data != -1)).ravel()\n",
    "#     tree_fall_indicies = (treefall == 1).ravel()\n",
    "#     # accumulate dataset \n",
    "#     X = []\n",
    "#     y = np.hstack([[0] * non_tree_fall_indicies.sum(), [1] * tree_fall_indicies.sum()])\n",
    "#     for var in ('height', 'aspect', 'slope'):\n",
    "#         data, lats, lons = load_specific_data(area=area, spec=var)\n",
    "#         _ = np.hstack([data.ravel()[non_tree_fall_indicies], data.ravel()[tree_fall_indicies]])\n",
    "#         X.append(_.tolist())\n",
    "#     X = np.array(X).T\n",
    "#     model = LinearDiscriminantAnalysis().fit(X, y)\n",
    "#     roc_auc = cross_val_score(model, X, y, cv=10, scoring='roc_auc')\n",
    "#     print(\"ROC_AUC: mean={}, std={}\".format(np.mean(roc_auc),np.std(roc_auc)))\n",
    "#     accuracy = cross_val_score(model, X, y, cv=10, scoring='balanced_accuracy')\n",
    "#     print(\"Accuracy: mean={}, std={}\".format(np.mean(accuracy),np.std(accuracy)))\n",
    "    \n",
    "#     # Performing PCA projections\n",
    "#     _, X_, _, y_ = train_test_split(X, y, stratify=y, test_size=0.01, random_state=0)\n",
    "#     X_proj = PCA(n_components=2).fit_transform(X_)\n",
    "#     plt.scatter(X_proj[y_==0, 0], X_proj[y_==0, 1], marker='o', color='r')\n",
    "#     plt.scatter(X_proj[y_==1, 0], X_proj[y_==1, 1], marker='s', color='b')\n",
    "#     plt.show()\n",
    "#     print(\"=\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
